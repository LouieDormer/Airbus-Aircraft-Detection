{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image,ImageDraw\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a string into a Python object\n",
    "def f(x):\n",
    "    return ast.literal_eval(x.rstrip('\\r\\n'))\n",
    "\n",
    "# Function to compute the bounding box of a given geometry\n",
    "def getBounds(geometry):\n",
    "    try:\n",
    "        arr = np.array(geometry).T\n",
    "        xmin = np.min(arr[0])\n",
    "        ymin = np.min(arr[1])\n",
    "        xmax = np.max(arr[0])\n",
    "        ymax = np.max(arr[1])\n",
    "        return (xmin, ymin, xmax, ymax)\n",
    "    except:\n",
    "        return np.nan # Need to return a value in case of error\n",
    "\n",
    "# Functions to compute the areas of the bounding box\n",
    "def getWidth(bounds):\n",
    "    try:\n",
    "        (xmin, ymin, xmax, ymax) = bounds\n",
    "        return np.abs(xmax - xmin)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def getHeight(bounds):\n",
    "    try:\n",
    "        (xmin, ymin, xmax, ymax) = bounds\n",
    "        return np.abs(ymax - ymin)\n",
    "    except:\n",
    "        return np.nan # Need to return a value in case of error\n",
    "\n",
    "# Functions to extract the absolute values of the x and y coordinates of the bounding box\n",
    "def getX(bounds):\n",
    "    try:\n",
    "        (xmin, ymin, xmax, ymax) = bounds\n",
    "        return np.abs(xmin)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def getY(bounds):\n",
    "    try:\n",
    "        (xmin, ymin, xmax, ymax) = bounds\n",
    "        return np.abs(ymin)\n",
    "    except:\n",
    "        return np.nan # Need to return a value in case of error\n",
    "\n",
    "\n",
    "class Averager:\n",
    "    \"\"\"\n",
    "   To be used for tracking loss and accuracy over multiple iterations of the training loop.\n",
    "\n",
    "    Attributes:\n",
    "        current_total (float): The cumulative sum of all values added so far.\n",
    "        iterations (float): The number of values added so far.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the Averager with a total of 0 and no iterations.\n",
    "        \"\"\"\n",
    "        self.current_total = 0.0  # Initialize the total sum to 0.\n",
    "        self.iterations = 0.0    # Initialize the iteration count to 0.\n",
    "\n",
    "    def send(self, value):\n",
    "        \"\"\"\n",
    "        Adds a new value to the running total and increments the iteration count.\n",
    "\n",
    "        Args:\n",
    "            value (float): The new value to include in the average.\n",
    "        \"\"\"\n",
    "        self.current_total += value  # Add the value to the cumulative total.\n",
    "        self.iterations += 1         # Increment the iteration count.\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        \"\"\"\n",
    "        Calculates and returns the current average.\n",
    "\n",
    "        Returns:\n",
    "            float: The current average of all values sent so far.\n",
    "                   Returns 0 if no values have been added.\n",
    "        \"\"\"\n",
    "        if self.iterations == 0:  # Avoid division by zero.\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations  # Calculate the average.\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the Averager, clearing the total and iteration count.\n",
    "        \"\"\"\n",
    "        self.current_total = 0.0  # Reset the total sum to 0.\n",
    "        self.iterations = 0.0    # Reset the iteration count to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Neural Network to detect aircraft in satellite images of an airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here is to train a neural network to detect aircraft in satellite images of an airport, splitting the dataset into training, validation and test\n",
    "sets.\n",
    "\n",
    "Information about the airplanes in the images has been provided via an annotations spreadsheet which contain bounding boxes for regions of interest, class of airplane and id for each respective image. This can be extracted and used for validation of the aircrafts detected by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(135, 522), (245, 522), (245, 600), (135, 600...</td>\n",
       "      <td>Airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(1025, 284), (1125, 284), (1125, 384), (1025,...</td>\n",
       "      <td>Airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(1058, 1503), (1130, 1503), (1130, 1568), (10...</td>\n",
       "      <td>Airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(813, 1518), (885, 1518), (885, 1604), (813, ...</td>\n",
       "      <td>Airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(594, 938), (657, 938), (657, 1012), (594, 10...</td>\n",
       "      <td>Airplane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  image_id  \\\n",
       "0   1  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "1   2  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "2   3  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "3   4  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "4   5  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "\n",
       "                                            geometry     class  \n",
       "0  [(135, 522), (245, 522), (245, 600), (135, 600...  Airplane  \n",
       "1  [(1025, 284), (1125, 284), (1125, 384), (1025,...  Airplane  \n",
       "2  [(1058, 1503), (1130, 1503), (1130, 1568), (10...  Airplane  \n",
       "3  [(813, 1518), (885, 1518), (885, 1604), (813, ...  Airplane  \n",
       "4  [(594, 938), (657, 938), (657, 1012), (594, 10...  Airplane  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME = \"/Users/louie/Documents/Visual Studio Code/ACT Work/Airbus-Aircraft-Detection\"\n",
    "directory_path = os.path.join(HOME, 'airbus-aircrafts-sample-dataset')\n",
    "image_path = os.path.join(directory_path, 'images')\n",
    "annotations_path = os.path.join(directory_path, 'annotations.csv')\n",
    "annotations = pd.read_csv(annotations_path)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>class</th>\n",
       "      <th>bounds</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(135, 522), (245, 522), (245, 600), (135, 600...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(135, 522, 245, 600)</td>\n",
       "      <td>110</td>\n",
       "      <td>78</td>\n",
       "      <td>135</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(1025, 284), (1125, 284), (1125, 384), (1025,...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(1025, 284, 1125, 384)</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1025</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(1058, 1503), (1130, 1503), (1130, 1568), (10...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(1058, 1503, 1130, 1568)</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>1058</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(813, 1518), (885, 1518), (885, 1604), (813, ...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(813, 1518, 885, 1604)</td>\n",
       "      <td>72</td>\n",
       "      <td>86</td>\n",
       "      <td>813</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(594, 938), (657, 938), (657, 1012), (594, 10...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(594, 938, 657, 1012)</td>\n",
       "      <td>63</td>\n",
       "      <td>74</td>\n",
       "      <td>594</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(451, 725), (524, 725), (524, 798), (451, 798...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(451, 725, 524, 798)</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>451</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(1543, 1437), (1614, 1437), (1614, 1497), (15...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(1543, 1437, 1614, 1497)</td>\n",
       "      <td>71</td>\n",
       "      <td>60</td>\n",
       "      <td>1543</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(1485, 1370), (1561, 1370), (1561, 1437), (14...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(1485, 1370, 1561, 1437)</td>\n",
       "      <td>76</td>\n",
       "      <td>67</td>\n",
       "      <td>1485</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(1968, 1624), (2053, 1624), (2053, 1687), (19...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(1968, 1624, 2053, 1687)</td>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>1968</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg</td>\n",
       "      <td>[(1659, 1674), (1733, 1674), (1733, 1746), (16...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>(1659, 1674, 1733, 1746)</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>1659</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  image_id  \\\n",
       "0   1  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "1   2  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "2   3  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "3   4  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "4   5  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "5   6  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "6   7  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "7   8  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "8   9  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "9  10  4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg   \n",
       "\n",
       "                                            geometry     class  \\\n",
       "0  [(135, 522), (245, 522), (245, 600), (135, 600...  Aircraft   \n",
       "1  [(1025, 284), (1125, 284), (1125, 384), (1025,...  Aircraft   \n",
       "2  [(1058, 1503), (1130, 1503), (1130, 1568), (10...  Aircraft   \n",
       "3  [(813, 1518), (885, 1518), (885, 1604), (813, ...  Aircraft   \n",
       "4  [(594, 938), (657, 938), (657, 1012), (594, 10...  Aircraft   \n",
       "5  [(451, 725), (524, 725), (524, 798), (451, 798...  Aircraft   \n",
       "6  [(1543, 1437), (1614, 1437), (1614, 1497), (15...  Aircraft   \n",
       "7  [(1485, 1370), (1561, 1370), (1561, 1437), (14...  Aircraft   \n",
       "8  [(1968, 1624), (2053, 1624), (2053, 1687), (19...  Aircraft   \n",
       "9  [(1659, 1674), (1733, 1674), (1733, 1746), (16...  Aircraft   \n",
       "\n",
       "                     bounds    w    h     x     y  \n",
       "0      (135, 522, 245, 600)  110   78   135   522  \n",
       "1    (1025, 284, 1125, 384)  100  100  1025   284  \n",
       "2  (1058, 1503, 1130, 1568)   72   65  1058  1503  \n",
       "3    (813, 1518, 885, 1604)   72   86   813  1518  \n",
       "4     (594, 938, 657, 1012)   63   74   594   938  \n",
       "5      (451, 725, 524, 798)   73   73   451   725  \n",
       "6  (1543, 1437, 1614, 1497)   71   60  1543  1437  \n",
       "7  (1485, 1370, 1561, 1437)   76   67  1485  1370  \n",
       "8  (1968, 1624, 2053, 1687)   85   63  1968  1624  \n",
       "9  (1659, 1674, 1733, 1746)   74   72  1659  1674  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(annotations_path, converters={'geometry': f, 'class': lambda o: 'Aircraft'})\n",
    "\n",
    "# Create bounds, width and height\n",
    "df.loc[:,'bounds'] = df.loc[:,'geometry'].apply(getBounds)\n",
    "df.loc[:,'w'] = df.loc[:,'bounds'].apply(getWidth)\n",
    "df.loc[:,'h'] = df.loc[:,'bounds'].apply(getHeight)\n",
    "df.loc[:,'x'] = df.loc[:,'bounds'].apply(getX)\n",
    "df.loc[:,'y'] = df.loc[:,'bounds'].apply(getY)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, these annotations and the dataset must be converted into a form that PyTorch can interpret, this will be done using `torch.utils.data` to create a custom class that stores the image ids and the image directory and the bounding box coordinates in the correct format. Once the images have been located, the image data is converted to a tensor and returned with its corresponding label in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AircraftDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initializes the custom Dataset to store the unique image IDs, DataFrame, image directory, and optionally any image transformations.\n",
    "        self.image_ids = dataframe['image_id'].unique()  \n",
    "        self.df = dataframe  \n",
    "        self.image_dir = image_dir  \n",
    "        self.transforms = transforms  # Optional data augmentation or preprocessing, currently set to None.\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # returns the number of unique images in the dataset\n",
    "        return self.image_ids.shape[0]  \n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # Loads the image at the given index, converts it to a tensor, reads any annotations and labels\n",
    "        # and returns them as a tuple\n",
    "\n",
    "        # Get the image ID for the given index.\n",
    "        image_id = self.image_ids[idx]\n",
    "\n",
    "        # Filter the DataFrame for records corresponding to this image ID.\n",
    "        records = self.df[self.df['image_id'] == image_id]\n",
    "\n",
    "        # Load the image from the image directory using OpenCV.\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_id}', cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Convert the image from BGR to RGB and normalize pixel values to [0, 1].\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0  # Normalize pixel values to the range [0, 1].\n",
    "\n",
    "        # Extract bounding box coordinates from the records.\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "        # Convert from [x, y, w, h] format to [x_min, y_min, x_max, y_max].\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]  # x_max = x_min + width\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]  # y_max = y_min + height\n",
    "\n",
    "        # Compute the area of each bounding box.\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)  # Convert to PyTorch tensor.\n",
    "\n",
    "        # Assign a label of 1 to all bounding boxes (single-class dataset).\n",
    "        labels = torch.ones((records.shape[0],), dtype=torch.int64).numpy()\n",
    "\n",
    "        # Assume that all instances are not part of a crowd (set `iscrowd` to 0).\n",
    "        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        # Create the target dictionary with required metadata.\n",
    "        target = {\n",
    "            'boxes': boxes,  # Bounding boxes.\n",
    "            'labels': labels,  # Object labels.\n",
    "            'image_id': torch.tensor([idx]),  # Image index as tensor.\n",
    "            'area': area,  # Area of each bounding box.\n",
    "            'iscrowd': iscrowd  # Crowd annotations.\n",
    "        }\n",
    "\n",
    "        # If transformations are specified, apply them to the image and bounding boxes.\n",
    "        if self.transforms:\n",
    "            # Prepare a sample dictionary for the transformations.\n",
    "            sample = {\n",
    "                'image': image,  # Input image.\n",
    "                'bboxes': target['boxes'],  # Bounding boxes.\n",
    "                'labels': labels  # Labels for the bounding boxes.\n",
    "            }\n",
    "            # Apply transformations.\n",
    "            sample = self.transforms(**sample)\n",
    "            # Update the image and bounding boxes after transformation.\n",
    "            image = sample['image']\n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        # Return the processed image, target dictionary, and image ID.\n",
    "        return image, target, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(Weights=None)\n",
    "#model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)\n",
    "#model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  # 2 total class: aircraft and background\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the dataset into training and validation sets\n",
    "\n",
    "Neural networks require both a training dataset for pattern recognition and a validation dataset to verify the learnt patterns are correct, this means splitting our dataset appropiately. An 80/20 training/validation split is usually used as a rule of thumb for neural networks as large datasets are typically required for effective pattern recognition, but these patterns still need to be evaulated using accurate data. \n",
    "\n",
    "Using a smaller split such as a 50/50 split can result in underfitting leading to insuffcient representation of the data distribution, especially in complex neural networks. Using a larger split such as a 90/10 split can result in overfitting which leads to unreliable evaluation metrics due to the validation set misrepresenting the full distribution, however this is sometimes required on small datasets. \n",
    "\n",
    "Taking into account the following factors, we will use a 90/10 split due to the size of the dataset being only 103 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_img = df.image_id.unique() # Get unique image ids from annotations spreadsheet\n",
    "train_inds, val_inds = train_test_split(range(unique_img.shape[0]), test_size= 0.1) # 90% train, 10% val\n",
    "\n",
    "train_df = df.iloc[train_inds] # Get training data\n",
    "valid_df = df.iloc[val_inds] # Get validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch): # Function to collate data samples into a batch\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_dataset = AircraftDataset(train_df, image_path, get_train_transform())\n",
    "valid_dataset = AircraftDataset(valid_df, image_path, get_valid_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset randomly into a train set and a test set removing any potential bias\n",
    "indices = torch.randperm(len(train_dataset)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and validation data loaders\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16, # how many samples per batch to load\n",
    "    shuffle=False, # disabling shuffling of the data, setting to True will randomize the data for each epoch, which prevents overfitting to the order of the data\n",
    "                   # setting to False ensures a deterministic order of the data, which is good for valiadation and testing runs\n",
    "    collate_fn=collate_fn # calling collate function\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
